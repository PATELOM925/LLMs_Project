{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": { 
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xYVqorQFKmY"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install weaviate-client"
      ],
      "metadata": {
        "id": "hL0aQb8RFWMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "3HHjqMbHFp4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "pORvFLz2F8Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Weaviate is Like the vector database,It allows us to store and retrieve data objects based on their semantic properties by indexing them with vectors."
      ],
      "metadata": {
        "id": "M_LzkojXP0bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate"
      ],
      "metadata": {
        "id": "InZPa4iKGCkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WEAVIATE_CLUSTER = 'https://42v8lolesogn12lavfflna.c0.europe-west3.gcp.weaviate.cloud'\n",
        "WEAVIATE_CLUSTER = \"https://btl6qhlrlovwk9cnxnxjw.c0.europe-west3.gcp.weaviate.cloud\"\n",
        "# WEAVIATE_API_KEY = 'rxSzp79vNnyI3pUppVM8FaRWBeWEDHAViuGr'\n",
        "WEAVIATE_API_KEY = \"rggVKqpoT6m0SiDwZlBrywcw1810MQ3WZg11\"\n",
        "HF_TOKEN = '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'"
      ],
      "metadata": {
        "id": "Ii72Qkg4GEXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "BqFitzX6Gi4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = weaviate.Client(\n",
        "    url = WEAVIATE_CLUSTER,\n",
        "    auth_client_secret= weaviate.AuthApiKey(WEAVIATE_API_KEY),\n",
        "    additional_headers={\n",
        "         \"X-HuggingFace-Api-Key\": HF_TOKEN\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "OC87HotDHMd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing client ready or not\n",
        "client.is_ready()"
      ],
      "metadata": {
        "id": "79zrZdSbHssn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = {\n",
        "    \"classes\": [\n",
        "        {\n",
        "            \"class\": \"try4\",\n",
        "            \"description\": \"Documents for RAG - try4\",\n",
        "            \"vectorizer\": \"text2vec-huggingface\",\n",
        "            \"moduleConfig\": {\"text2vec-huggingface\": {\"model\": \"sentence-transformers/all-MiniLM-L6-v2\", \"type\": \"text\"}},\n",
        "            \"properties\": [\n",
        "                {\n",
        "                    \"dataType\": [\"text\"],\n",
        "                    \"description\": \"The content of the paragraph\",\n",
        "                    \"moduleConfig\": {\n",
        "                        \"text2vec-huggingface\": {\n",
        "                            \"skip\": False,\n",
        "                            \"vectorizePropertyName\": False,\n",
        "                        }\n",
        "                    },\n",
        "                    \"name\": \"content\",\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "POZ--9lRHwuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# client.schema.create(sc)"
      ],
      "metadata": {
        "id": "ebKKFmBawzyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    schema = client.schema.get()\n",
        "    print(\"Connection successful. Schema:\", schema)\n",
        "except weaviate.exceptions.AuthenticationFailedException as e:\n",
        "    print(\"Authentication failed:\", e)\n",
        "except weaviate.exceptions.RequestError as e:\n",
        "    print(\"Request error:\", e)"
      ],
      "metadata": {
        "id": "VNZDXj9Vwi9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.schema.get()"
      ],
      "metadata": {
        "id": "32Kg43LLIUzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing Embedding\n",
        "from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever"
      ],
      "metadata": {
        "id": "31Hbrz8lLKWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = WeaviateHybridSearchRetriever(\n",
        "    alpha = 0.5,\n",
        "    client = client,\n",
        "    index_name = \"Try4\",\n",
        "    text_key = \"content\",\n",
        "    attributes= [],\n",
        "    create_schema_if_missing=True\n",
        ")"
      ],
      "metadata": {
        "id": "cSBzrUO2L_cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\""
      ],
      "metadata": {
        "id": "K4LSAgzqOgxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "GxUi5FMhPeLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "tsU7sBNqXWVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import ( AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline, )\n",
        "from langchain import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "-grb1mM0Pk2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for loading 4-bit quantized model\n",
        "def load_quantized_model(model_name: str):\n",
        "    \"\"\"\n",
        "    model_name: Name or path of the model to be loaded.\n",
        "    return: Loaded quantized model.\n",
        "    \"\"\"\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        low_cpu_mem_usage=True\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        quantization_config=bnb_config,\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "NHXjDU-3QaVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing tokenizer\n",
        "def initialize_tokenizer(model_name: str):\n",
        "    \"\"\"\n",
        "    model_name: Name or path of the model for tokenizer initialization.\n",
        "    return: Initialized tokenizer.\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, return_token_type_ids=False)\n",
        "    tokenizer.bos_token_id = 1  # Set beginning of sentence token id\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "nxW6W6NURn6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = initialize_tokenizer(model_name)"
      ],
      "metadata": {
        "id": "P3JJ24piRqDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_quantized_model(model_name)"
      ],
      "metadata": {
        "id": "ugYDLw9MRPW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline = pipeline(\n",
        "#     \"text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     use_cache=True,\n",
        "#     device_map=\"auto\",\n",
        "#     #max_length=2048,\n",
        "#     do_sample=True,\n",
        "#     top_k=5,\n",
        "#     max_new_tokens=100,\n",
        "#     num_return_sequences=1,\n",
        "#     eos_token_id=tokenizer.eos_token_id,\n",
        "#     pad_token_id=tokenizer.pad_token_id,\n",
        "# )\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    use_cache=True,\n",
        "    device_map=\"auto\",\n",
        "    #max_length=2048,\n",
        "    do_sample=True,\n",
        "    top_k=5,\n",
        "    max_new_tokens=100,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "10x07YgiRTgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "WyH4YXMRR2r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "dD2FPnnuSP-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "DawhNCePSWPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path = '/content/Statistics.pdf'\n",
        "path = '/content/Machien-Learning-and-AI.pdf'"
      ],
      "metadata": {
        "id": "r0pSnoqqSaI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(path)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "8livDvGwR_5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs)"
      ],
      "metadata": {
        "id": "_Ry0Yg7aStAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.add_documents(docs)"
      ],
      "metadata": {
        "id": "YVL_DwvTSv0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "rz6fv_xiSub2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[32])"
      ],
      "metadata": {
        "id": "moEr1fliTeI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(retriever.invoke(\"What is Data Science\")[0].page_content)"
      ],
      "metadata": {
        "id": "l8Ui2VaHTpOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke('What are the applications of AI ?',score=True)"
      ],
      "metadata": {
        "id": "QDg9I4-QT_Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "dGQ4TqsaUlC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = (\n",
        "    \"Use the given context to answer the question. \"\n",
        "    \"If you don't know the answer, say you don't know. \"\n",
        "    \"Use three sentence maximum and keep the answer concise. \"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{query}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "fktgwSVMZBWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you do not have the relevant information needed to provide a verified answer, don't try to make up an answer.\n",
        "When providing an answer, aim for clarity and precision. Position yourself as a knowledgeable authority on the topic, but also be mindful to explain the information in a manner that is accessible and comprehensible to those without a technical background.\n",
        "Always say \"Do you have any more questions pertaining to this instrument?\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "EOIKzjBjZBMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain"
      ],
      "metadata": {
        "id": "HXz6jw5qZAnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,)"
      ],
      "metadata": {
        "id": "40wdnnxOZVlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = hybrid_chain.invoke(\"what is Data Science?\")\n",
        "print(a1)"
      ],
      "metadata": {
        "id": "wlzMJuWlZVax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a1['result'])"
      ],
      "metadata": {
        "id": "zT90O2yBZVYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1=\"What is Data Science?\"\n",
        "response = hybrid_chain.invoke({\"query\":q1})"
      ],
      "metadata": {
        "id": "zGh4cUq5Ztb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "PJwyhtksZw4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()} |\n",
        "    prompt |\n",
        "    llm\n",
        ")"
      ],
      "metadata": {
        "id": "WGZKiPYdZyXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q2 = q1"
      ],
      "metadata": {
        "id": "ZIapotvOZ2-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a2 = rag_chain.invoke(q2)"
      ],
      "metadata": {
        "id": "sytL_RfDZ907"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a2)"
      ],
      "metadata": {
        "id": "9r1d3SMDaFwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwqcdaIUicm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
